{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui0av11EHSS5",
        "outputId": "6fa28719-2d42-4f5c-ab67-02f1726dc6ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests pandas numpy scikit-learn tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n"
      ],
      "metadata": {
        "id": "s-NoocMMHtvz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv(\"/content/Customer-Dataset.csv\")\n",
        "retailers = pd.read_csv(\"/content/Retail-Dataset.csv\")\n",
        "logistics = pd.read_csv(\"/content/Logistic-Dataset.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IXmulDm5H3na"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENWEATHER_API_KEY = \"1bb571682b348fe67ff37524f894fa37\"  # Replace with your actual key\n",
        "\n"
      ],
      "metadata": {
        "id": "wZ7Fvbh_JLvs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_live_weather(city):\n",
        "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    if data.get(\"main\") and data.get(\"wind\"):\n",
        "        return {\n",
        "            \"temp\": data[\"main\"].get(\"temp\", 25),\n",
        "            \"wind\": data[\"wind\"].get(\"speed\", 5),\n",
        "            \"rain\": data.get(\"rain\", {}).get(\"1h\", 0.0)\n",
        "        }\n",
        "    else:\n",
        "        return {\"temp\": 25, \"wind\": 5, \"rain\": 0.0}\n"
      ],
      "metadata": {
        "id": "kVekmPNPJPQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_risk_label(weather):\n",
        "    return 1 if weather[\"rain\"] > 10 or weather[\"wind\"] > 15 else 0\n",
        "\n"
      ],
      "metadata": {
        "id": "0el85m0mIC_S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_features, risk_labels = [], []\n",
        "\n",
        "for _, row in customers.iterrows():\n",
        "    city = \"San Francisco\"  # Default if no city\n",
        "    weather = get_live_weather(city)\n",
        "    label = assign_risk_label(weather)\n",
        "    weather_features.append([weather[\"temp\"], weather[\"wind\"], weather[\"rain\"]])\n",
        "    risk_labels.append(label)\n",
        "\n",
        "X = np.array(weather_features)\n",
        "y = np.array(risk_labels)\n",
        "X_lstm = np.repeat(X[:, np.newaxis, :], 7, axis=1)  # sequence length 7\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y, test_size=0.2)\n",
        "\n",
        "model_customer = Sequential([\n",
        "    LSTM(32, input_shape=(7, 3), return_sequences=False),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_customer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_customer.fit(X_train, y_train, epochs=10, batch_size=16)\n",
        "model_customer.save(\"customer_lstm_model.h5\")\n"
      ],
      "metadata": {
        "id": "_yyEtDyTKCvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6b3c7e-4ac6-4ec5-a1d7-795df423e1a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0582\n",
            "Epoch 2/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1922e-06\n",
            "Epoch 3/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2947e-07\n",
            "Epoch 4/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.2678e-07\n",
            "Epoch 5/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1760e-07\n",
            "Epoch 6/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.7194e-08\n",
            "Epoch 7/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0578e-08\n",
            "Epoch 8/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5394e-08\n",
            "Epoch 9/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6293e-08\n",
            "Epoch 10/10\n",
            "\u001b[1m778/778\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0652e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retail_subset = retailers[['City', 'Shipping_Method', 'Payment_Method', 'Order_Status']].dropna()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in retail_subset.columns:\n",
        "    le = LabelEncoder()\n",
        "    retail_subset[col] = le.fit_transform(retail_subset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "retail_weather = [get_live_weather(city) for city in retailers['City'].fillna(\"San Francisco\")]\n",
        "weather_df = pd.DataFrame(retail_weather)\n",
        "\n",
        "retail_features = pd.concat([retail_subset.reset_index(drop=True), weather_df.reset_index(drop=True)], axis=1)\n",
        "retail_labels = [assign_risk_label(w) for w in retail_weather]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_ret = scaler.fit_transform(retail_features)\n",
        "y_ret = np.array(retail_labels)\n",
        "\n",
        "model_retailer = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_ret.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_retailer.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_retailer.fit(X_ret, y_ret, epochs=10, batch_size=16)\n",
        "model_retailer.save(\"retailer_mlp_model.h5\")\n"
      ],
      "metadata": {
        "id": "N9KOdn66KASM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602c57c1-5945-431d-b48e-d36c922ab566"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logi_subset = logistics[['product_name', 'order_city', 'shipping_mode']].dropna()\n",
        "label_encoders_logi = {}\n",
        "\n",
        "for col in logi_subset.columns:\n",
        "    le = LabelEncoder()\n",
        "    logi_subset[col] = le.fit_transform(logi_subset[col])\n",
        "    label_encoders_logi[col] = le\n",
        "\n",
        "logi_weather = [get_live_weather(city) for city in logistics['order_city'].fillna(\"San Francisco\")]\n",
        "logi_weather_df = pd.DataFrame(logi_weather)\n",
        "\n",
        "logi_features = pd.concat([logi_subset.reset_index(drop=True), logi_weather_df.reset_index(drop=True)], axis=1)\n",
        "logi_labels = [assign_risk_label(w) for w in logi_weather]\n",
        "\n",
        "X_log = scaler.fit_transform(logi_features)\n",
        "y_log = np.array(logi_labels)\n",
        "\n",
        "model_logistics = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_log.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_logistics.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_logistics.fit(X_log, y_log, epochs=10, batch_size=16)\n",
        "model_logistics.save(\"logistics_mlp_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "E8KNXD-wKEcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d0407f-76f8-4342-9c8c-dd888429d3a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m972/972\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "iwA3W_vJMRWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be56573-31bd-4585-acbc-fb7e2997cdf0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit-folium\n"
      ],
      "metadata": {
        "id": "c-HaTvisWyA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3573c26b-f800-478f-865f-5833f1aaf534"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-folium\n",
            "  Downloading streamlit_folium-0.25.0-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: streamlit>=1.35.0 in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (1.45.0)\n",
            "Requirement already satisfied: folium!=0.15.0,>=0.13 in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (0.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (3.1.6)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2025.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->streamlit-folium) (3.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.35.0->streamlit-folium) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35.0->streamlit-folium) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35.0->streamlit-folium) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (1.17.0)\n",
            "Downloading streamlit_folium-0.25.0-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m328.4/328.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: streamlit-folium\n",
            "Successfully installed streamlit-folium-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openrouteservice\n"
      ],
      "metadata": {
        "id": "4qmcv-m_Zgco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f36585-7e8d-4f18-85ed-cecd38d8ade5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openrouteservice\n",
            "  Downloading openrouteservice-2.3.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.11/dist-packages (from openrouteservice) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (2025.4.26)\n",
            "Downloading openrouteservice-2.3.3-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: openrouteservice\n",
            "Successfully installed openrouteservice-2.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import openrouteservice\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import folium\n",
        "from streamlit_folium import folium_static\n",
        "from transformers import pipeline\n",
        "import os\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# Hugging Face API Key (Set your key in the environment variable or directly here)\n",
        "HF_API_KEY = \"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\"\n",
        "os.environ[\"HF_HOME\"] = HF_API_KEY  # Set the Hugging Face API key\n",
        "\n",
        "# ORS API Key\n",
        "ORS_API_KEY = \"5b3ce3597851110001cf6248a9522fa41b27439588c559d4621706db\"\n",
        "client = openrouteservice.Client(key=ORS_API_KEY)\n",
        "\n",
        "\n",
        "# Hugging Face model for text generation\n",
        "hf_pipeline = pipeline(\"text-generation\", model=\"gpt2\")  # You can replace with any suitable model\n",
        "\n",
        "# Load models\n",
        "model_customer = load_model(\"/content/customer_lstm_model.h5\")\n",
        "model_retailer = load_model(\"/content/retailer_mlp_model.h5\")\n",
        "model_logistics = load_model(\"/content/logistics_mlp_model.h5\")\n",
        "\n",
        "# API Key for OpenWeather API\n",
        "OPENWEATHER_API_KEY = \"1bb571682b348fe67ff37524f894fa37\"\n",
        "\n",
        "def get_weather(city):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    if data.get(\"main\") and data.get(\"wind\") and \"coord\" in data:\n",
        "        return {\n",
        "            \"temp\": data[\"main\"].get(\"temp\", 25),\n",
        "            \"wind\": data[\"wind\"].get(\"speed\", 5),\n",
        "            \"rain\": data.get(\"rain\", {}).get(\"1h\", 0.0),\n",
        "            \"lat\": data[\"coord\"][\"lat\"],\n",
        "            \"lon\": data[\"coord\"][\"lon\"]\n",
        "        }\n",
        "    else:\n",
        "        return {\"temp\": 25, \"wind\": 5, \"rain\": 0.0, \"lat\": 0.0, \"lon\": 0.0}\n",
        "\n",
        "def generate_insight(city, product, score):\n",
        "    context = (\n",
        "        f\"A customer in {city} has ordered a {product}. \"\n",
        "        f\"The estimated delivery risk score is {score}. \"\n",
        "        \"Based on this, provide a recommendation to the customer about whether to proceed with the order, and explain why.\"\n",
        "    )\n",
        "    result = hf_pipeline(context, max_new_tokens=200, do_sample=True, top_p=0.9, temperature=0.7)\n",
        "    return result[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "# Title\n",
        "st.title(\"AI-Powered Supply Chain Risk Predictor\")\n",
        "\n",
        "# Tabs\n",
        "tab1, tab2, tab3 = st.tabs([\"Customer\", \"Retailer\", \"Logistics\"])\n",
        "\n",
        "# Tab 1: Customer Risk Prediction\n",
        "with tab1:\n",
        "    st.header(\"Customer Risk Prediction\")\n",
        "\n",
        "    customer_city = st.text_input(\"Enter your city\")\n",
        "    product = st.text_input(\"Enter the product you want to order\")\n",
        "\n",
        "    if customer_city and product:\n",
        "        if st.button(\"Check Risk and Get Recommendation\"):\n",
        "            with st.spinner(\"Fetching weather and analyzing risk...\"):\n",
        "                try:\n",
        "                    weather = get_weather(customer_city)\n",
        "                    st.write(\"### Weather Conditions at Your Location:\")\n",
        "                    st.json(weather)\n",
        "\n",
        "                    # Show on map\n",
        "                    m = folium.Map(location=[weather[\"lat\"], weather[\"lon\"]], zoom_start=10)\n",
        "                    folium.Marker([weather[\"lat\"], weather[\"lon\"]], tooltip=\"Customer Location\").add_to(m)\n",
        "                    folium_static(m)\n",
        "\n",
        "                    # Prepare input for model\n",
        "                    input_array = np.array([[weather[\"temp\"], weather[\"wind\"], weather[\"rain\"]]] * 7).reshape(1, 7, 3)\n",
        "                    risk_score = int(model_customer.predict(input_array)[0][0] * 100)\n",
        "\n",
        "                    st.metric(\"ğŸ“Š Delivery Risk Score\", risk_score)\n",
        "\n",
        "                    # Generate AI-based insight\n",
        "                    insight = generate_insight(customer_city, product, risk_score)\n",
        "                    st.subheader(\"ğŸ“ AI Insight and Suggested Action\")\n",
        "                    st.info(insight)\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error during risk assessment: {e}\")\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Retailer Delivery Route Details\")\n",
        "\n",
        "    customer_city = st.text_input(\"Customer Location\")\n",
        "    warehouse_city = st.text_input(\"Warehouse Location\", key=\"warehouse_location_retailer\")\n",
        "\n",
        "    if customer_city and warehouse_city:\n",
        "        warehouse_weather = get_weather(warehouse_city)\n",
        "        customer_weather = get_weather(customer_city)\n",
        "\n",
        "        # Routing using ORS (OpenRouteService)\n",
        "        start_coords = (warehouse_weather[\"lon\"], warehouse_weather[\"lat\"])\n",
        "        end_coords = (customer_weather[\"lon\"], customer_weather[\"lat\"])\n",
        "\n",
        "        try:\n",
        "            route = client.directions(\n",
        "                coordinates=[start_coords, end_coords],\n",
        "                profile='driving-car',\n",
        "                format='geojson',\n",
        "                instructions=True\n",
        "            )\n",
        "\n",
        "            # Visualize on map\n",
        "            m = folium.Map(location=[(warehouse_weather[\"lat\"] + customer_weather[\"lat\"]) / 2,\n",
        "                                     (warehouse_weather[\"lon\"] + customer_weather[\"lon\"]) / 2], zoom_start=6)\n",
        "            folium.Marker(\n",
        "                [warehouse_weather[\"lat\"], warehouse_weather[\"lon\"]],\n",
        "                tooltip=\"Warehouse\", icon=folium.Icon(color=\"blue\")\n",
        "            ).add_to(m)\n",
        "\n",
        "            folium.Marker(\n",
        "                [customer_weather[\"lat\"], customer_weather[\"lon\"]],\n",
        "                tooltip=\"Customer\", icon=folium.Icon(color=\"green\")\n",
        "            ).add_to(m)\n",
        "\n",
        "            # Draw route polyline\n",
        "            folium.PolyLine(\n",
        "                locations=[(coord[1], coord[0]) for coord in route['features'][0]['geometry']['coordinates']],\n",
        "                color='purple', weight=4\n",
        "            ).add_to(m)\n",
        "\n",
        "            folium_static(m)\n",
        "\n",
        "            # Extract route details\n",
        "            properties = route[\"features\"][0][\"properties\"]\n",
        "            summary = properties[\"summary\"]\n",
        "            steps = properties.get(\"segments\", [])[0].get(\"steps\", [])\n",
        "\n",
        "            route_details = {\n",
        "                \"from\": warehouse_city,\n",
        "                \"to\": customer_city,\n",
        "                \"distance_km\": round(summary[\"distance\"] / 1000, 2),\n",
        "                \"duration_minutes\": round(summary[\"duration\"] / 60, 2),\n",
        "                \"steps\": [\n",
        "                    {\n",
        "                        \"instruction\": step[\"instruction\"],\n",
        "                        \"distance_m\": step[\"distance\"],\n",
        "                        \"duration_s\": step[\"duration\"],\n",
        "                        \"type\": step.get(\"type\")\n",
        "                    }\n",
        "                    for step in steps\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            st.subheader(\"Route Summary\")\n",
        "            st.write(f\"**Distance:** {route_details['distance_km']} km\")\n",
        "            st.write(f\"**Estimated Time:** {route_details['duration_minutes']} minutes\")\n",
        "\n",
        "            st.subheader(\"Route Details\")\n",
        "            st.json(route_details)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Route generation error: {e}\")\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"Logistics Warehouse Route Details\")\n",
        "\n",
        "    city = st.text_input(\"Destination City\")\n",
        "    product = st.text_input(\"Product to Deliver\")\n",
        "    warehouse_city = st.text_input(\"Warehouse Location\", key=\"warehouse_location_logistics\")\n",
        "\n",
        "    if city and warehouse_city and product:\n",
        "        destination_weather = get_weather(city)\n",
        "        warehouse_weather = get_weather(warehouse_city)\n",
        "\n",
        "        start_coords = (warehouse_weather[\"lon\"], warehouse_weather[\"lat\"])\n",
        "        end_coords = (destination_weather[\"lon\"], destination_weather[\"lat\"])\n",
        "\n",
        "        try:\n",
        "            route = client.directions(\n",
        "                coordinates=[start_coords, end_coords],\n",
        "                profile='driving-car',\n",
        "                format='geojson',\n",
        "                instructions=True\n",
        "            )\n",
        "\n",
        "            # Display map\n",
        "            m = folium.Map(location=[\n",
        "                (warehouse_weather[\"lat\"] + destination_weather[\"lat\"]) / 2,\n",
        "                (warehouse_weather[\"lon\"] + destination_weather[\"lon\"]) / 2\n",
        "            ], zoom_start=6)\n",
        "\n",
        "            folium.Marker(\n",
        "                [warehouse_weather[\"lat\"], warehouse_weather[\"lon\"]],\n",
        "                tooltip=\"Warehouse\", icon=folium.Icon(color=\"red\")\n",
        "            ).add_to(m)\n",
        "\n",
        "            folium.Marker(\n",
        "                [destination_weather[\"lat\"], destination_weather[\"lon\"]],\n",
        "                tooltip=\"Destination\", icon=folium.Icon(color=\"orange\")\n",
        "            ).add_to(m)\n",
        "\n",
        "            folium.PolyLine(\n",
        "                locations=[(c[1], c[0]) for c in route['features'][0]['geometry']['coordinates']],\n",
        "                color='darkred', weight=4\n",
        "            ).add_to(m)\n",
        "\n",
        "            folium_static(m)\n",
        "\n",
        "            # Extract route info\n",
        "            properties = route[\"features\"][0][\"properties\"]\n",
        "            summary = properties[\"summary\"]\n",
        "            steps = properties.get(\"segments\", [])[0].get(\"steps\", [])\n",
        "\n",
        "            route_details = {\n",
        "                \"from\": warehouse_city,\n",
        "                \"to\": city,\n",
        "                \"product\": product,\n",
        "                \"distance_km\": round(summary[\"distance\"] / 1000, 2),\n",
        "                \"duration_minutes\": round(summary[\"duration\"] / 60, 2),\n",
        "                \"steps\": [\n",
        "                    {\n",
        "                        \"instruction\": step[\"instruction\"],\n",
        "                        \"distance_m\": step[\"distance\"],\n",
        "                        \"duration_s\": step[\"duration\"],\n",
        "                        \"type\": step.get(\"type\")\n",
        "                    }\n",
        "                    for step in steps\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            st.subheader(\"Logistics Route Summary\")\n",
        "            st.write(f\"**Distance:** {route_details['distance_km']} km\")\n",
        "            st.write(f\"**Estimated Time:** {route_details['duration_minutes']} minutes\")\n",
        "\n",
        "            st.subheader(\"Route Details\")\n",
        "            st.json(route_details)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Routing error: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiMdH6hJg4tO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492809a5-f534-43ad-ab1d-0caafa1d4192"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py"
      ],
      "metadata": {
        "id": "3FdtyIziLgoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96762a9b-7a9e-4d45-f2ee-5d58787e9f31"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.168.199.122:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "q-dK_QHnLkiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39400057-ff9f-4eff-8b6d-8223d525d450"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.7)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any existing ngrok and Streamlit processes\n",
        "!pkill -f streamlit\n",
        "!pkill -f ngrok\n",
        "\n",
        "# Re-run ngrok authentication (Replace with your token)\n",
        "!ngrok authtoken 2sh8tZRTzmljkt4YiY7hv3Qv1SI_fY1azBK9xS6q9eqN2vzp\n",
        "\n",
        "# Start Streamlit again\n",
        "!nohup streamlit run app.py --server.port 8501 &\n",
        "\n",
        "# Reconnect ngrok to expose Streamlit\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\" New Public Link: {public_url}\")"
      ],
      "metadata": {
        "id": "pHckHt5PLbQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf6bb82-78b2-4304-c96b-e17a93c04b44"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "nohup: appending output to 'nohup.out'\n",
            " New Public Link: NgrokTunnel: \"https://040c-34-168-199-122.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}